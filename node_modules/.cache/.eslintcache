[{"/Users/andre/speech-to-text-polly/src/index.js":"1","/Users/andre/speech-to-text-polly/src/App.js":"2","/Users/andre/speech-to-text-polly/src/reportWebVitals.js":"3","/Users/andre/speech-to-text-polly/src/TextToSpeech.js":"4","/Users/andre/speech-to-text-polly/src/SpeechToText.js":"5","/Users/andre/speech-to-text-polly/src/ApiCallComponent.js":"6","/Users/andre/speech-to-text-polly/src/all.js":"7"},{"size":535,"mtime":1695815788911,"results":"8","hashOfConfig":"9"},{"size":635,"mtime":1695819745738,"results":"10","hashOfConfig":"9"},{"size":362,"mtime":1695815788911,"results":"11","hashOfConfig":"9"},{"size":2156,"mtime":1695816946392,"results":"12","hashOfConfig":"9"},{"size":1513,"mtime":1695816573168,"results":"13","hashOfConfig":"9"},{"size":1812,"mtime":1695816843936,"results":"14","hashOfConfig":"9"},{"size":4102,"mtime":1695819700102,"results":"15","hashOfConfig":"9"},{"filePath":"16","messages":"17","suppressedMessages":"18","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},"owiiao",{"filePath":"19","messages":"20","suppressedMessages":"21","errorCount":0,"fatalErrorCount":0,"warningCount":8,"fixableErrorCount":0,"fixableWarningCount":0,"source":"22"},{"filePath":"23","messages":"24","suppressedMessages":"25","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"26","messages":"27","suppressedMessages":"28","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"29","messages":"30","suppressedMessages":"31","errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"32"},{"filePath":"33","messages":"34","suppressedMessages":"35","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"36","messages":"37","suppressedMessages":"38","errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"39"},"/Users/andre/speech-to-text-polly/src/index.js",[],[],"/Users/andre/speech-to-text-polly/src/App.js",["40","41","42","43","44","45","46","47"],[],"import React, { useState, useEffect } from 'react';\nimport SpeechToText from './SpeechToText';\nimport TextToSpeech from './TextToSpeech';\nimport ApiCallComponent from './ApiCallComponent';\nimport All from './all';\n\n\n\nimport './App.css';\n\nfunction App() {\n  const [transcribedText, setTranscribedText] = useState('');\n  const [apiResponse, setApiResponse] = useState('');\n\n  const handleTranscription = (text) => {\n    setTranscribedText(text);\n  };\n\n  const handleApiResponse = (response) => {\n    setApiResponse(response);\n  };\n\n  return (\n    <div className=\"App\">\n\n      \n      \n      <All />\n    </div>\n  );\n}\n\nexport default App;\n","/Users/andre/speech-to-text-polly/src/reportWebVitals.js",[],[],"/Users/andre/speech-to-text-polly/src/TextToSpeech.js",[],[],"/Users/andre/speech-to-text-polly/src/SpeechToText.js",["48"],[],"import React, { useState, useEffect } from 'react';\n\nconst SpeechToText = () => {\n  const [transcript, setTranscript] = useState('');\n  const [isListening, setIsListening] = useState(false);\n  const [isSupported, setIsSupported] = useState(true);\n\n  const toggleListening = () => {\n    if (isListening) {\n      recognition.stop();\n    } else {\n      recognition.start();\n    }\n  };\n\n  const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();\n\n  recognition.onstart = () => {\n    setIsListening(true);\n  };\n\n  recognition.onresult = (event) => {\n    const result = event.results[0][0].transcript;\n    setTranscript(result);\n  };\n\n  recognition.onend = () => {\n    setIsListening(false);\n  };\n\n  recognition.onerror = (event) => {\n    console.error('Speech recognition error:', event.error);\n    setIsListening(false);\n  };\n\n  useEffect(() => {\n    if (!('SpeechRecognition' in window) && !('webkitSpeechRecognition' in window)) {\n      setIsSupported(false);\n    }\n\n    return () => {\n      recognition.stop();\n    };\n  }, []);\n\n  return (\n    <div>\n      <h2>Speech to Text</h2>\n      {isSupported ? (\n        <>\n          <button onClick={toggleListening}>\n            {isListening ? 'Stop Listening' : 'Start Listening'}\n          </button>\n          {isListening && <p>Listening...</p>}\n          <p>Transcript: {transcript}</p>\n        </>\n      ) : (\n        <p>Speech recognition is not supported in this browser.</p>\n      )}\n    </div>\n  );\n};\n\nexport default SpeechToText;\n","/Users/andre/speech-to-text-polly/src/ApiCallComponent.js",[],[],"/Users/andre/speech-to-text-polly/src/all.js",["49"],[],"import React, { useState, useEffect } from 'react';\nimport axios from 'axios';\nimport AWS from 'aws-sdk';\n\nconst TalkComponent = () => {\n  const [isListening, setIsListening] = useState(false);\n  const [isSupported, setIsSupported] = useState(true);\n  const [transcribedText, setTranscribedText] = useState('');\n  const [audioUrl, setAudioUrl] = useState('');\n  const [message, setMessage] = useState('');\n  const [apiResponse, setApiResponse] = useState('');\n\n  const toggleListening = () => {\n    if (isListening) {\n      recognition.stop();\n    } else {\n      recognition.start();\n    }\n  };\n\n  const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();\n\n  recognition.onstart = () => {\n    setIsListening(true);\n  };\n\n  recognition.onresult = (event) => {\n    const result = event.results[0][0].transcript;\n    setTranscribedText(result);\n  };\n\n  recognition.onend = () => {\n    setIsListening(false);\n  };\n\n  recognition.onerror = (event) => {\n    console.error('Speech recognition error:', event.error);\n    setIsListening(false);\n  };\n\n  const handleTextToSpeech = async (textToSpeak) => {\n    try {\n      setAudioUrl('');\n      AWS.config.update({\n        accessKeyId: 'AKIAR22DSRP6A3INZCOZ',\n        secretAccessKey: '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',\n        region: 'eu-west-1',\n      });\n      \n\n      const polly = new AWS.Polly();\n      const response = await polly.synthesizeSpeech({\n        Text: textToSpeak,\n        OutputFormat: 'mp3',\n        VoiceId: 'Matthew',\n      }).promise();\n\n      const blob = new Blob([response.AudioStream], { type: 'audio/mpeg' });\n      const url = URL.createObjectURL(blob);\n\n      setAudioUrl(url);\n      setMessage('Audio synthesis complete.');\n    } catch (error) {\n      setMessage(\n        error.code === 'NoCredentialsError'\n          ? 'AWS credentials not found. Make sure to configure your AWS credentials.'\n          : `An error occurred: ${error.message}`\n      );\n    }\n  };\n\n  const handleSendToApi = async () => {\n    try {\n      const serverEndpoint = 'https://deva.ark4.xyz/api'; // Updated endpoint URL\n  \n      const requestData = {\n        user_input: transcribedText, // Assuming the API expects 'user_input'\n      };\n  \n      const response = await axios.post(\n        serverEndpoint,\n        requestData,\n        {\n          headers: {\n            'Content-Type': 'application/json',\n          },\n        }\n      );\n  \n      const apiResponseText = response.data.response;\n      setApiResponse(apiResponseText);\n  \n      // Automatically start text-to-speech when the API response is received\n      if (apiResponseText) {\n        await handleTextToSpeech(apiResponseText);\n      }\n    } catch (error) {\n      console.error('Error:', error);\n    }\n  };\n  \n\n  useEffect(() => {\n    if (!('SpeechRecognition' in window) && !('webkitSpeechRecognition' in window)) {\n      setIsSupported(false);\n    }\n\n    return () => {\n      recognition.stop();\n    };\n  }, []);\n\n  return (\n    <div>\n      <h2>Speech to Text</h2>\n      {isSupported && (\n        <>\n          <button onClick={toggleListening}>\n            {isListening ? 'Stop Listening' : 'Start Listening'}\n          </button>\n          {isListening && <p>Listening...</p>}\n        </>\n      )}\n      {!isSupported && <p>Speech recognition is not supported in this browser.</p>}\n      <h3>Transcribed Text:</h3>\n      <p>{transcribedText}</p>\n      {transcribedText && (\n        <>\n          <button onClick={handleSendToApi}>Send to API</button>\n          <h2>API Response Text</h2>\n          <p>{apiResponse}</p>\n          <h3>Text to Speech Conversion</h3>\n          <button onClick={() => handleTextToSpeech(apiResponse)}>Convert to Speech</button>\n          <p>{message}</p>\n          {audioUrl && (\n            <div>\n              <h4>Audio Output</h4>\n              <audio controls>\n                <source src={audioUrl} type=\"audio/mpeg\" />\n                Your browser does not support the audio element.\n              </audio>\n            </div>\n          )}\n        </>\n      )}\n    </div>\n  );\n};\n\nexport default TalkComponent;\n",{"ruleId":"50","severity":1,"message":"51","line":1,"column":27,"nodeType":"52","messageId":"53","endLine":1,"endColumn":36},{"ruleId":"50","severity":1,"message":"54","line":2,"column":8,"nodeType":"52","messageId":"53","endLine":2,"endColumn":20},{"ruleId":"50","severity":1,"message":"55","line":3,"column":8,"nodeType":"52","messageId":"53","endLine":3,"endColumn":20},{"ruleId":"50","severity":1,"message":"56","line":4,"column":8,"nodeType":"52","messageId":"53","endLine":4,"endColumn":24},{"ruleId":"50","severity":1,"message":"57","line":12,"column":10,"nodeType":"52","messageId":"53","endLine":12,"endColumn":25},{"ruleId":"50","severity":1,"message":"58","line":13,"column":10,"nodeType":"52","messageId":"53","endLine":13,"endColumn":21},{"ruleId":"50","severity":1,"message":"59","line":15,"column":9,"nodeType":"52","messageId":"53","endLine":15,"endColumn":28},{"ruleId":"50","severity":1,"message":"60","line":19,"column":9,"nodeType":"52","messageId":"53","endLine":19,"endColumn":26},{"ruleId":"61","severity":1,"message":"62","line":44,"column":6,"nodeType":"63","endLine":44,"endColumn":8,"suggestions":"64"},{"ruleId":"61","severity":1,"message":"62","line":111,"column":6,"nodeType":"63","endLine":111,"endColumn":8,"suggestions":"65"},"no-unused-vars","'useEffect' is defined but never used.","Identifier","unusedVar","'SpeechToText' is defined but never used.","'TextToSpeech' is defined but never used.","'ApiCallComponent' is defined but never used.","'transcribedText' is assigned a value but never used.","'apiResponse' is assigned a value but never used.","'handleTranscription' is assigned a value but never used.","'handleApiResponse' is assigned a value but never used.","react-hooks/exhaustive-deps","React Hook useEffect has a missing dependency: 'recognition'. Either include it or remove the dependency array.","ArrayExpression",["66"],["67"],{"desc":"68","fix":"69"},{"desc":"68","fix":"70"},"Update the dependencies array to be: [recognition]",{"range":"71","text":"72"},{"range":"73","text":"72"},[1053,1055],"[recognition]",[2966,2968]]