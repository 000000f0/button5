{"ast":null,"code":"var _jsxFileName = \"/Users/andre/chatfront/src/SpeachToText.jsx\",\n  _s = $RefreshSig$();\nimport React, { useState, useEffect } from 'react';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nimport { Fragment as _Fragment } from \"react/jsx-dev-runtime\";\nconst SpeechToText = () => {\n  _s();\n  const [transcript, setTranscript] = useState('');\n  const [isListening, setIsListening] = useState(false);\n  const [isSupported, setIsSupported] = useState(true);\n  const toggleListening = () => {\n    if (isListening) {\n      recognition.stop();\n    } else {\n      recognition.start();\n    }\n  };\n  useEffect(() => {\n    if ('SpeechRecognition' in window || 'webkitSpeechRecognition' in window) {\n      const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();\n      recognition.onstart = () => {\n        setIsListening(true);\n      };\n      recognition.onresult = event => {\n        const result = event.results[0][0].transcript;\n        setTranscript(result);\n      };\n      recognition.onend = () => {\n        setIsListening(false);\n      };\n      recognition.onerror = event => {\n        console.error('Speech recognition error:', event.error);\n        setIsListening(false);\n      };\n      setIsSupported(true);\n      setIsListening(false);\n      recognition.lang = 'en-US';\n      recognition.continuous = true;\n      recognition.interimResults = true;\n      return () => {\n        recognition.stop();\n      };\n    } else {\n      setIsSupported(false);\n    }\n  }, []);\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    children: [/*#__PURE__*/_jsxDEV(\"h2\", {\n      children: \"Speech to Text\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 54,\n      columnNumber: 7\n    }, this), isSupported ? /*#__PURE__*/_jsxDEV(_Fragment, {\n      children: [/*#__PURE__*/_jsxDEV(\"button\", {\n        onClick: toggleListening,\n        children: isListening ? 'Stop Listening' : 'Start Listening'\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 57,\n        columnNumber: 11\n      }, this), isListening && /*#__PURE__*/_jsxDEV(\"p\", {\n        children: \"Listening...\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 60,\n        columnNumber: 27\n      }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n        children: [\"Transcript: \", transcript]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 61,\n        columnNumber: 11\n      }, this)]\n    }, void 0, true) : /*#__PURE__*/_jsxDEV(\"p\", {\n      children: \"Speech recognition is not supported in this browser.\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 64,\n      columnNumber: 9\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 53,\n    columnNumber: 5\n  }, this);\n};\n_s(SpeechToText, \"kHd0yrfLp/5cApzE8c8WnSpBq8Y=\");\n_c = SpeechToText;\nexport default SpeechToText;\nvar _c;\n$RefreshReg$(_c, \"SpeechToText\");","map":{"version":3,"names":["React","useState","useEffect","jsxDEV","_jsxDEV","Fragment","_Fragment","SpeechToText","_s","transcript","setTranscript","isListening","setIsListening","isSupported","setIsSupported","toggleListening","recognition","stop","start","window","SpeechRecognition","webkitSpeechRecognition","onstart","onresult","event","result","results","onend","onerror","console","error","lang","continuous","interimResults","children","fileName","_jsxFileName","lineNumber","columnNumber","onClick","_c","$RefreshReg$"],"sources":["/Users/andre/chatfront/src/SpeachToText.jsx"],"sourcesContent":["import React, { useState, useEffect } from 'react';\n\nconst SpeechToText = () => {\n  const [transcript, setTranscript] = useState('');\n  const [isListening, setIsListening] = useState(false);\n  const [isSupported, setIsSupported] = useState(true);\n  \n  const toggleListening = () => {\n    if (isListening) {\n      recognition.stop();\n    } else {\n      recognition.start();\n    }\n  };\n\n  useEffect(() => {\n    if ('SpeechRecognition' in window || 'webkitSpeechRecognition' in window) {\n      const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();\n\n      recognition.onstart = () => {\n        setIsListening(true);\n      };\n\n      recognition.onresult = (event) => {\n        const result = event.results[0][0].transcript;\n        setTranscript(result);\n      };\n\n      recognition.onend = () => {\n        setIsListening(false);\n      };\n\n      recognition.onerror = (event) => {\n        console.error('Speech recognition error:', event.error);\n        setIsListening(false);\n      };\n\n      setIsSupported(true);\n      setIsListening(false);\n      recognition.lang = 'en-US';\n      recognition.continuous = true;\n      recognition.interimResults = true;\n\n      return () => {\n        recognition.stop();\n      };\n    } else {\n      setIsSupported(false);\n    }\n  }, []);\n\n  return (\n    <div>\n      <h2>Speech to Text</h2>\n      {isSupported ? (\n        <>\n          <button onClick={toggleListening}>\n            {isListening ? 'Stop Listening' : 'Start Listening'}\n          </button>\n          {isListening && <p>Listening...</p>}\n          <p>Transcript: {transcript}</p>\n        </>\n      ) : (\n        <p>Speech recognition is not supported in this browser.</p>\n      )}\n    </div>\n  );\n};\n\nexport default SpeechToText;\n"],"mappings":";;AAAA,OAAOA,KAAK,IAAIC,QAAQ,EAAEC,SAAS,QAAQ,OAAO;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAAA,SAAAC,QAAA,IAAAC,SAAA;AAEnD,MAAMC,YAAY,GAAGA,CAAA,KAAM;EAAAC,EAAA;EACzB,MAAM,CAACC,UAAU,EAAEC,aAAa,CAAC,GAAGT,QAAQ,CAAC,EAAE,CAAC;EAChD,MAAM,CAACU,WAAW,EAAEC,cAAc,CAAC,GAAGX,QAAQ,CAAC,KAAK,CAAC;EACrD,MAAM,CAACY,WAAW,EAAEC,cAAc,CAAC,GAAGb,QAAQ,CAAC,IAAI,CAAC;EAEpD,MAAMc,eAAe,GAAGA,CAAA,KAAM;IAC5B,IAAIJ,WAAW,EAAE;MACfK,WAAW,CAACC,IAAI,CAAC,CAAC;IACpB,CAAC,MAAM;MACLD,WAAW,CAACE,KAAK,CAAC,CAAC;IACrB;EACF,CAAC;EAEDhB,SAAS,CAAC,MAAM;IACd,IAAI,mBAAmB,IAAIiB,MAAM,IAAI,yBAAyB,IAAIA,MAAM,EAAE;MACxE,MAAMH,WAAW,GAAG,KAAKG,MAAM,CAACC,iBAAiB,IAAID,MAAM,CAACE,uBAAuB,EAAE,CAAC;MAEtFL,WAAW,CAACM,OAAO,GAAG,MAAM;QAC1BV,cAAc,CAAC,IAAI,CAAC;MACtB,CAAC;MAEDI,WAAW,CAACO,QAAQ,GAAIC,KAAK,IAAK;QAChC,MAAMC,MAAM,GAAGD,KAAK,CAACE,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAACjB,UAAU;QAC7CC,aAAa,CAACe,MAAM,CAAC;MACvB,CAAC;MAEDT,WAAW,CAACW,KAAK,GAAG,MAAM;QACxBf,cAAc,CAAC,KAAK,CAAC;MACvB,CAAC;MAEDI,WAAW,CAACY,OAAO,GAAIJ,KAAK,IAAK;QAC/BK,OAAO,CAACC,KAAK,CAAC,2BAA2B,EAAEN,KAAK,CAACM,KAAK,CAAC;QACvDlB,cAAc,CAAC,KAAK,CAAC;MACvB,CAAC;MAEDE,cAAc,CAAC,IAAI,CAAC;MACpBF,cAAc,CAAC,KAAK,CAAC;MACrBI,WAAW,CAACe,IAAI,GAAG,OAAO;MAC1Bf,WAAW,CAACgB,UAAU,GAAG,IAAI;MAC7BhB,WAAW,CAACiB,cAAc,GAAG,IAAI;MAEjC,OAAO,MAAM;QACXjB,WAAW,CAACC,IAAI,CAAC,CAAC;MACpB,CAAC;IACH,CAAC,MAAM;MACLH,cAAc,CAAC,KAAK,CAAC;IACvB;EACF,CAAC,EAAE,EAAE,CAAC;EAEN,oBACEV,OAAA;IAAA8B,QAAA,gBACE9B,OAAA;MAAA8B,QAAA,EAAI;IAAc;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAI,CAAC,EACtBzB,WAAW,gBACVT,OAAA,CAAAE,SAAA;MAAA4B,QAAA,gBACE9B,OAAA;QAAQmC,OAAO,EAAExB,eAAgB;QAAAmB,QAAA,EAC9BvB,WAAW,GAAG,gBAAgB,GAAG;MAAiB;QAAAwB,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAC7C,CAAC,EACR3B,WAAW,iBAAIP,OAAA;QAAA8B,QAAA,EAAG;MAAY;QAAAC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAG,CAAC,eACnClC,OAAA;QAAA8B,QAAA,GAAG,cAAY,EAACzB,UAAU;MAAA;QAAA0B,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAI,CAAC;IAAA,eAC/B,CAAC,gBAEHlC,OAAA;MAAA8B,QAAA,EAAG;IAAoD;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAG,CAC3D;EAAA;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OACE,CAAC;AAEV,CAAC;AAAC9B,EAAA,CAjEID,YAAY;AAAAiC,EAAA,GAAZjC,YAAY;AAmElB,eAAeA,YAAY;AAAC,IAAAiC,EAAA;AAAAC,YAAA,CAAAD,EAAA"},"metadata":{},"sourceType":"module","externalDependencies":[]}